"""Main entry point for Rocket Screener.

Usage:
    python -m app.run --date 2025-01-10 --dry-run
    python -m app.run --date 2025-01-10 --publish
"""

import argparse
import logging
import sys
import time
from datetime import date, datetime
from pathlib import Path
from typing import Optional

from app.config import TZ, AppConfig, FMPConfig, load_config
from app.publish.publish_posts import ArticleContent, publish_articles

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger("rocketscreener")


# Universe: S&P 500 + hot stocks (will be loaded dynamically in v3+)
SEED_UNIVERSE = {
    # Mega caps
    "AAPL", "MSFT", "GOOGL", "GOOG", "AMZN", "NVDA", "META", "TSLA",
    "BRK.B", "JPM", "JNJ", "V", "UNH", "HD", "PG", "MA", "DIS",
    # Tech / AI
    "AMD", "INTC", "CRM", "ADBE", "NFLX", "PYPL", "AVGO", "QCOM",
    "MU", "AMAT", "LRCX", "KLAC", "ASML", "TSM", "ARM", "SMCI",
    # Other notable
    "COST", "WMT", "XOM", "CVX", "LLY", "NVO", "ABBV", "MRK", "PFE",
}


def parse_args() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Rocket Screener - ç»çµ¦æ•£æˆ¶çš„æ©Ÿæ§‹ç´šåˆ†æž",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument(
        "--date",
        type=str,
        default=None,
        help="Target date in YYYY-MM-DD format (default: today)",
    )

    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "--dry-run",
        action="store_true",
        help="Generate articles without publishing (output to out/)",
    )
    group.add_argument(
        "--publish",
        action="store_true",
        help="Generate and publish articles to Ghost as drafts (default)",
    )
    group.add_argument(
        "--publish-live",
        action="store_true",
        help="Generate, publish and send newsletter (Article 1 only)",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default="out",
        help="Output directory for dry-run mode (default: out)",
    )

    parser.add_argument(
        "--no-fmp",
        action="store_true",
        help="Skip FMP API calls (use placeholder data)",
    )

    return parser.parse_args()


def get_target_date(date_str: Optional[str]) -> date:
    """Parse target date from string or return today."""
    if date_str:
        return datetime.strptime(date_str, "%Y-%m-%d").date()
    return datetime.now(TZ).date()


def generate_article1_with_fmp(
    target_date: date,
    fmp_config: FMPConfig,
) -> ArticleContent:
    """Generate Article 1 using FMP data."""
    from app.evidence.build_article1 import build_article1_evidence
    from app.features.event_scoring import score_events, select_top_events
    from app.ingest.fmp_client import FMPClient
    from app.llm.writer import render_article1
    from app.normalize.dedupe import deduplicate_news, filter_by_universe

    logger.info("æ­£åœ¨å¾ž FMP å–å¾—è³‡æ–™...")

    fmp = FMPClient(fmp_config)

    # Get S&P 500 constituents and merge with seed
    try:
        sp500 = set(fmp.get_sp500_constituents())
        universe = SEED_UNIVERSE | sp500
        logger.info(f"Universe å¤§å°: {len(universe)}")
    except Exception as e:
        logger.warning(f"ç„¡æ³•å–å¾— S&P 500 æˆåˆ†è‚¡: {e}")
        universe = SEED_UNIVERSE

    # Get news
    logger.info("å–å¾—æ–°èž...")
    stock_news = fmp.get_stock_news(limit=100)
    general_news = fmp.get_general_news(limit=50)
    all_news = stock_news + general_news
    logger.info(f"å–å¾— {len(all_news)} å‰‡æ–°èž")

    # Deduplicate
    events = deduplicate_news(all_news)

    # Filter by universe
    events = filter_by_universe(events, universe)

    # Get price changes for scoring
    price_changes = {}
    try:
        movers = fmp.get_gainers_losers()
        for item in movers.get("gainers", []) + movers.get("losers", []):
            symbol = item.get("symbol")
            change = item.get("changesPercentage", 0)
            if symbol:
                price_changes[symbol] = change
    except Exception as e:
        logger.warning(f"ç„¡æ³•å–å¾—æ¼²è·Œå¹…: {e}")

    # Score and select
    scored = score_events(events, price_changes)
    top_events = select_top_events(scored, min_count=5, max_count=8)

    # Build evidence pack with LLM analysis
    evidence = build_article1_evidence(target_date, fmp, top_events, price_changes)

    # Render article
    markdown = render_article1(evidence)

    return ArticleContent(
        article_num=1,
        title=f"ç¾Žè‚¡ç›¤å¾Œæ™¨å ± | {target_date.strftime('%Y/%m/%d')}",
        markdown_content=markdown,
        tags=["daily-brief", "market-update"],
        excerpt="æ¯æ—¥ç¾Žè‚¡ç›¤å¾Œç²¾é¸ç„¦é»žï¼ŒæŽŒæ¡å¸‚å ´è„ˆå‹•ã€‚",
    )


def generate_placeholder_article1(target_date: date) -> ArticleContent:
    """Generate placeholder Article 1 (no FMP)."""
    date_display = target_date.strftime("%Y/%m/%d")

    return ArticleContent(
        article_num=1,
        title=f"ç¾Žè‚¡ç›¤å¾Œæ™¨å ± | {date_display}",
        markdown_content=f"""# ç¾Žè‚¡ç›¤å¾Œæ™¨å ± | {date_display}

> {date_display} | ç¾Žè‚¡è“‹å€«å“¥

---

## ä¸‰è¡Œå¿«è®€

- å¸‚å ´ç­‰å¾…é‡è¦ç¶“æ¿Ÿæ•¸æ“šå…¬å¸ƒ
- ç§‘æŠ€è‚¡è¡¨ç¾åˆ†æ­§
- å‚µå¸‚ç¶­æŒç©©å®š

---

## å¸‚å ´å¿«ç…§

| æŒ‡æ¨™ | æ”¶ç›¤ | æ¼²è·Œ | æ¼²è·Œå¹… |
|------|------|------|--------|
| S&P 500 | -- | -- | -- |
| Nasdaq | -- | -- | -- |
| é“ç“Šå·¥æ¥­ | -- | -- | -- |
| 10Y æ®–åˆ©çŽ‡ | -- | -- | -- |
| åŽŸæ²¹ (WTI) | -- | -- | -- |
| é»ƒé‡‘ | -- | -- | -- |
| BTC | -- | -- | -- |

---

## ä»Šæ—¥ç„¦é»ž

> â„¹ï¸ ä½¿ç”¨ --no-fmp æ¨¡å¼ï¼Œé¡¯ç¤ºä½”ä½å…§å®¹ã€‚è¨­å®š FMP_API_KEY ç’°å¢ƒè®Šæ•¸ä»¥å–å¾—çœŸå¯¦æ•¸æ“šã€‚

### 1. å¸‚å ´è§€æœ›

**ç™¼ç”Ÿä»€éº¼äº‹ï¼Ÿ**
æŠ•è³‡è€…ç­‰å¾…é‡è¦ç¶“æ¿Ÿæ•¸æ“šå…¬å¸ƒã€‚

**ç‚ºä½•é‡è¦ï¼Ÿ**
æ•¸æ“šå°‡å½±éŸ¿ Fed åˆ©çŽ‡æ±ºç­–æ–¹å‘ã€‚

**å¯èƒ½å½±éŸ¿**
çŸ­æœŸå¸‚å ´æ³¢å‹•å¯èƒ½åŠ åŠ‡ã€‚

**ä¸‹ä¸€æ­¥è§€å¯Ÿ**
é—œæ³¨æ•¸æ“šå…¬å¸ƒå¾Œçš„å¸‚å ´åæ‡‰ã€‚

ðŸ“Ž ä¾†æºï¼š[1](https://example.com)

---

## ä»Šæ™šå¿…çœ‹

- ç›¤å¾Œè²¡å ±å…¬å¸ƒå‹•æ…‹
- äºžæ´²å¸‚å ´é–‹ç›¤åæ‡‰
- é‡è¦ç¶“æ¿Ÿæ•¸æ“šå…¬å¸ƒ

---

## é¢¨éšªæç¤º

æœ¬æ–‡å…§å®¹åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡å»ºè­°ã€‚æŠ•è³‡æœ‰é¢¨éšªï¼Œå…¥å¸‚éœ€è¬¹æ…Žã€‚éŽåŽ»ç¸¾æ•ˆä¸ä»£è¡¨æœªä¾†è¡¨ç¾ã€‚

---

*Rocket Screener â€” ç»çµ¦æ•£æˆ¶çš„æ©Ÿæ§‹ç´šåˆ†æž*
""",
        tags=["daily-brief", "market-update"],
        excerpt="æ¯æ—¥ç¾Žè‚¡ç›¤å¾Œç²¾é¸ç„¦é»žï¼ŒæŽŒæ¡å¸‚å ´è„ˆå‹•ã€‚",
    )


def generate_placeholder_article2(target_date: date) -> ArticleContent:
    """Generate placeholder Article 2 (will be real in v3)."""
    date_display = target_date.strftime("%Y/%m/%d")

    return ArticleContent(
        article_num=2,
        title="å€‹è‚¡æ·±åº¦ï½œNVDA è¼é”ï¼šAI æ™¶ç‰‡éœ¸ä¸»çš„ä¼°å€¼è§£æž",
        slug_suffix="nvda",
        markdown_content=f"""# å€‹è‚¡æ·±åº¦ï½œNVDA è¼é”ï¼šAI æ™¶ç‰‡éœ¸ä¸»çš„ä¼°å€¼è§£æž

> {date_display} | ç¾Žè‚¡è“‹å€«å“¥ | NVDA

---

## å…¬å¸æ¦‚è¦½

NVIDIAï¼ˆè¼é”ï¼‰æ˜¯å…¨çƒé ˜å…ˆçš„ GPU èˆ‡ AI é‹ç®—å¹³å°å…¬å¸ã€‚

**é—œéµæ•¸æ“š**
- å¸‚å€¼ï¼š--
- ç”¢æ¥­ï¼šç§‘æŠ€ / åŠå°Žé«”
- ä¸Šå¸‚äº¤æ˜“æ‰€ï¼šNASDAQ

---

## åŸºæœ¬é¢åˆ†æž

> â„¹ï¸ å®Œæ•´æ•¸æ“šå°‡åœ¨ v3 ç‰ˆæœ¬å‘ˆç¾ã€‚

---

## è²¡å‹™é¢åˆ†æž

| æŒ‡æ¨™ | æœ€æ–°å­£ | å‰ä¸€å­£ | YoY |
|------|--------|--------|-----|
| ç‡Ÿæ”¶ | -- | -- | -- |
| æ¯›åˆ©çŽ‡ | -- | -- | -- |
| æ·¨åˆ© | -- | -- | -- |

---

## ä¼°å€¼åˆ†æž

### åˆç†åƒ¹æŽ¨ä¼°

| æƒ…å¢ƒ | å‡è¨­ | ç›®æ¨™åƒ¹ | æ½›åœ¨ç©ºé–“ |
|------|------|--------|----------|
| ðŸ» Bear | æˆé•·æ”¾ç·© | -- | -- |
| âš–ï¸ Base | ç¶­æŒè¶¨å‹¢ | -- | -- |
| ðŸ‚ Bull | åŠ é€Ÿæˆé•· | -- | -- |

---

## å‚¬åŒ–åŠ‘èˆ‡é¢¨éšª

### æ½›åœ¨å‚¬åŒ–åŠ‘
- è³‡æ–™ä¸­å¿ƒéœ€æ±‚æŒçºŒæˆé•·
- æ–°ç”¢å“ç™¼å¸ƒ

### ä¸»è¦é¢¨éšª
- ç«¶çˆ­åŠ åŠ‡
- ä¾›æ‡‰éˆé™åˆ¶

---

## é¢¨éšªæç¤º

æœ¬æ–‡å…§å®¹åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡å»ºè­°ã€‚æŠ•è³‡æœ‰é¢¨éšªï¼Œå…¥å¸‚éœ€è¬¹æ…Žã€‚éŽåŽ»ç¸¾æ•ˆä¸ä»£è¡¨æœªä¾†è¡¨ç¾ã€‚ä½œè€…å¯èƒ½æŒæœ‰æˆ–äº¤æ˜“æœ¬æ–‡æåŠä¹‹è‚¡ç¥¨ã€‚

---

*Rocket Screener â€” ç»çµ¦æ•£æˆ¶çš„æ©Ÿæ§‹ç´šåˆ†æž*
""",
        tags=["deep-dive", "NVDA", "semiconductor", "AI"],
        excerpt="æ·±å…¥è§£æž NVIDIA çš„åŸºæœ¬é¢ã€è²¡å‹™èˆ‡ä¼°å€¼ã€‚",
    )


def generate_article2_with_fmp(
    target_date: date,
    fmp_config: FMPConfig,
    scored_events: list,
    price_changes: dict[str, float],
    ghost_config=None,
) -> ArticleContent:
    """Generate Article 2 using FMP data and hot stock scoring."""
    from app.evidence.build_article2 import build_article2_evidence
    from app.features.hot_stock_scoring import score_hot_stocks
    from app.features.valuation_chart import generate_valuation_chart_from_evidence
    from app.ingest.fmp_client import FMPClient
    from app.llm.writer import render_article2

    logger.info("ç”Ÿæˆæ–‡ç«  2ï¼šç†±é–€è‚¡æ·±åº¦åˆ†æž...")

    fmp = FMPClient(fmp_config)

    # Build news ticker counts from scored events
    news_ticker_counts = {}
    for ev in scored_events:
        for ticker in ev.event.tickers:
            news_ticker_counts[ticker] = news_ticker_counts.get(ticker, 0) + 1

    # Get universe
    try:
        sp500 = set(fmp.get_sp500_constituents())
        universe = SEED_UNIVERSE | sp500
    except Exception:
        universe = SEED_UNIVERSE

    # Score and select hot stock
    hot_stocks = score_hot_stocks(fmp, universe, news_ticker_counts)
    if not hot_stocks:
        logger.warning("ç„¡ç†±é–€è‚¡å¯é¸ï¼Œä½¿ç”¨é è¨­")
        return generate_placeholder_article2(target_date)

    selected = hot_stocks[0]
    logger.info(f"é¸ä¸­ç†±é–€è‚¡: {selected.ticker} (score: {selected.score:.2f})")

    # Build evidence pack with transcript config if available
    from app.config import load_config as get_app_config

    app_config = get_app_config()
    transcript_config = app_config.transcript if app_config else None
    evidence = build_article2_evidence(target_date, fmp, selected, transcript_config)

    # Generate valuation chart (v4)
    chart_path = None
    chart_url = None
    try:
        output_dir = Path("out") / "charts" / target_date.strftime("%Y-%m-%d")
        chart_path = generate_valuation_chart_from_evidence(evidence, output_dir)
        if chart_path:
            logger.info(f"ä¼°å€¼åœ–å·²ç”Ÿæˆ: {chart_path}")
            # Upload to Ghost if config available
            if ghost_config:
                try:
                    from app.publish.ghost_client import GhostClient

                    ghost = GhostClient(ghost_config)
                    chart_url = ghost.upload_image(chart_path)
                    evidence.valuation_chart_url = chart_url
                    logger.info(f"ä¼°å€¼åœ–å·²ä¸Šå‚³: {chart_url}")
                except Exception as e:
                    logger.warning(f"ä¼°å€¼åœ–ä¸Šå‚³å¤±æ•—: {e}")
    except Exception as e:
        logger.warning(f"ä¼°å€¼åœ–ç”Ÿæˆå¤±æ•—: {e}")

    # Render article
    markdown = render_article2(evidence)

    return ArticleContent(
        article_num=2,
        title=f"å€‹è‚¡æ·±åº¦ï½œ{selected.ticker} {selected.name}",
        slug_suffix=selected.ticker.lower(),
        markdown_content=markdown,
        tags=["deep-dive", selected.ticker, evidence.sector.lower()],
        excerpt=f"æ·±å…¥è§£æž {selected.name} çš„åŸºæœ¬é¢ã€è²¡å‹™èˆ‡ä¼°å€¼ã€‚",
    )


def generate_article3_with_fmp(
    target_date: date,
    fmp_config: FMPConfig,
    scored_events: list,
    output_dir: Path = None,
) -> ArticleContent:
    """Generate Article 3 using FMP data and theme detection."""
    from app.evidence.build_article3 import build_article3_evidence, generate_supply_chain_chart_for_article3
    from app.features.theme_detection import detect_themes
    from app.ingest.fmp_client import FMPClient
    from app.llm.writer import render_article3

    logger.info("ç”Ÿæˆæ–‡ç«  3ï¼šç”¢æ¥­ä¸»é¡Œè¶¨å‹¢...")

    fmp = FMPClient(fmp_config)

    # Detect themes from events
    headlines = [e.event.headline for e in scored_events] if scored_events else []

    # Build ticker counts from events
    ticker_counts = {}
    for ev in scored_events:
        for ticker in ev.event.tickers:
            ticker_counts[ticker] = ticker_counts.get(ticker, 0) + 1

    themes = detect_themes(headlines, ticker_counts)

    if not themes:
        logger.warning("ç„¡ä¸»é¡Œå¯é¸ï¼Œä½¿ç”¨é è¨­ AI ä¼ºæœå™¨")
        from app.features.theme_detection import DetectedTheme

        themes = [DetectedTheme(
            theme_id="ai-server",
            display_name="AI ä¼ºæœå™¨",
            score=1.0,
            matched_keywords=["AI"],
            relevant_tickers=["NVDA", "AMD", "TSM"],
            trigger_events=["AI éœ€æ±‚æŒçºŒæˆé•·"],
        )]

    selected_theme = themes[0]
    logger.info(f"é¸ä¸­ä¸»é¡Œ: {selected_theme.display_name}")

    # Build evidence pack with recent news for LLM
    evidence = build_article3_evidence(
        target_date, fmp, selected_theme, recent_news=headlines[:5]
    )

    # Generate supply chain chart (v8)
    if output_dir is None:
        output_dir = Path("output") / target_date.isoformat()
    chart_path = generate_supply_chain_chart_for_article3(evidence, output_dir)
    if chart_path:
        logger.info(f"ç”¢æ¥­éˆåœ–å·²ç”Ÿæˆ: {chart_path}")

    # Render article
    markdown = render_article3(evidence)

    return ArticleContent(
        article_num=3,
        title=f"ç”¢æ¥­è¶¨å‹¢ï½œ{selected_theme.display_name}",
        slug_suffix=selected_theme.theme_id,
        markdown_content=markdown,
        tags=["theme", selected_theme.theme_id],
        excerpt=f"è§£æž {selected_theme.display_name} çš„é—œéµè¶¨å‹¢èˆ‡æŠ•è³‡æ©Ÿæœƒã€‚",
    )


def generate_placeholder_article3(target_date: date) -> ArticleContent:
    """Generate placeholder Article 3 (fallback only)."""
    date_display = target_date.strftime("%Y/%m/%d")

    return ArticleContent(
        article_num=3,
        title="ç”¢æ¥­è¶¨å‹¢ï½œAI ä¼ºæœå™¨ä¾›æ‡‰éˆï¼š2025 é—œéµè¶¨å‹¢",
        slug_suffix="ai-server",
        markdown_content=f"""# ç”¢æ¥­è¶¨å‹¢ï½œAI ä¼ºæœå™¨ä¾›æ‡‰éˆï¼š2025 é—œéµè¶¨å‹¢

> {date_display} | ç¾Žè‚¡è“‹å€«å“¥ | AI ä¼ºæœå™¨

---

## ç‚ºä½•ç¾åœ¨é—œæ³¨ï¼Ÿ

AI åŸºç¤Žè¨­æ–½éœ€æ±‚æŒçºŒæ”€å‡ï¼Œå¸¶å‹•æ•´é«”ä¾›æ‡‰éˆå—æƒ ã€‚

---

## é¢¨éšªæç¤º

æœ¬æ–‡å…§å®¹åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡å»ºè­°ã€‚

---

*Rocket Screener â€” ç»çµ¦æ•£æˆ¶çš„æ©Ÿæ§‹ç´šåˆ†æž*
""",
        tags=["theme", "AI", "semiconductor", "supply-chain"],
        excerpt="è§£æž AI ä¼ºæœå™¨ä¾›æ‡‰éˆçš„é—œéµè¶¨å‹¢èˆ‡æŠ•è³‡æ©Ÿæœƒã€‚",
    )


def generate_articles(
    target_date: date,
    config: Optional[AppConfig],
    use_fmp: bool = True,
) -> list[ArticleContent]:
    """Generate all 3 articles.

    Args:
        target_date: Date for articles
        config: App configuration (None for dry-run without config)
        use_fmp: Whether to use FMP API

    Returns:
        List of 3 ArticleContent objects
    """
    from app.features.event_scoring import score_events, select_top_events
    from app.ingest.fmp_client import FMPClient
    from app.normalize.dedupe import deduplicate_news, filter_by_universe

    articles = []
    scored_events = []
    price_changes = {}

    # Get FMP data if available
    if use_fmp and config and config.fmp:
        try:
            fmp = FMPClient(config.fmp)

            # Get S&P 500 constituents and merge with seed
            try:
                sp500 = set(fmp.get_sp500_constituents())
                universe = SEED_UNIVERSE | sp500
            except Exception:
                universe = SEED_UNIVERSE

            # Get news
            stock_news = fmp.get_stock_news(limit=100)
            general_news = fmp.get_general_news(limit=50)
            all_news = stock_news + general_news

            # Deduplicate and filter
            events = deduplicate_news(all_news)
            events = filter_by_universe(events, universe)

            # Get price changes
            try:
                movers = fmp.get_gainers_losers()
                for item in movers.get("gainers", []) + movers.get("losers", []):
                    symbol = item.get("symbol")
                    change = item.get("changesPercentage", 0)
                    if symbol:
                        price_changes[symbol] = change
            except Exception:
                pass

            # Score events
            scored_events = score_events(events, price_changes)
            scored_events = select_top_events(scored_events, min_count=5, max_count=8)

            # Add SEC events (v6)
            try:
                from app.ingest.sec_client import SECClient

                sec_client = SECClient()
                # Check top tickers from scored events for SEC filings
                top_tickers = set()
                for ev in scored_events:
                    top_tickers.update(ev.event.tickers[:2])

                for ticker in list(top_tickers)[:10]:  # Limit API calls
                    sec_events = sec_client.detect_events(ticker, days_back=3)
                    for sec_ev in sec_events:
                        if sec_ev.importance == "high":
                            # Add SEC event to scored events
                            from app.normalize.dedupe import NewsEvent
                            from app.features.event_scoring import ScoredEvent

                            news_ev = NewsEvent(
                                headline=f"[SEC {sec_ev.form_type}] {ticker}: {sec_ev.description}",
                                text=f"{ticker} filed {sec_ev.form_type} with SEC on {sec_ev.filing_date}.",
                                tickers=[ticker],
                                source_urls=[sec_ev.url],
                                published_at=None,
                            )
                            sec_scored = ScoredEvent(
                                event=news_ev,
                                event_type="sec_filing",
                                score=0.7,
                                price_score=0,
                                recency_score=0.8,
                                novelty_score=0.6,
                            )
                            scored_events.append(sec_scored)
                            logger.info(f"Added SEC event: {sec_ev.form_type} for {ticker}")

                # Re-sort and limit
                scored_events = sorted(scored_events, key=lambda x: x.score, reverse=True)[:8]
            except Exception as e:
                logger.warning(f"SEC event detection failed: {e}")

        except Exception as e:
            logger.error(f"FMP å–å¾—å¤±æ•—: {e}")

    # Article 1: Daily Brief
    if use_fmp and config and config.fmp and scored_events:
        try:
            article1 = generate_article1_with_fmp(target_date, config.fmp)
        except Exception as e:
            logger.error(f"æ–‡ç«  1 ç”Ÿæˆå¤±æ•—: {e}")
            article1 = generate_placeholder_article1(target_date)
    else:
        article1 = generate_placeholder_article1(target_date)

    articles.append(article1)

    # Article 2: Hot Stock Deep Dive
    if use_fmp and config and config.fmp:
        try:
            article2 = generate_article2_with_fmp(
                target_date, config.fmp, scored_events, price_changes,
                ghost_config=config.ghost if config else None
            )
        except Exception as e:
            logger.error(f"æ–‡ç«  2 ç”Ÿæˆå¤±æ•—: {e}")
            article2 = generate_placeholder_article2(target_date)
    else:
        article2 = generate_placeholder_article2(target_date)

    articles.append(article2)

    # Article 3: Theme/Sector Trends
    if use_fmp and config and config.fmp:
        try:
            article3 = generate_article3_with_fmp(
                target_date, config.fmp, scored_events
            )
        except Exception as e:
            logger.error(f"æ–‡ç«  3 ç”Ÿæˆå¤±æ•—: {e}")
            article3 = generate_placeholder_article3(target_date)
    else:
        article3 = generate_placeholder_article3(target_date)

    articles.append(article3)

    return articles


def run(args: argparse.Namespace) -> int:
    """Main execution flow."""
    start_time = time.time()

    logger.info("=" * 60)
    logger.info("Rocket Screener å•Ÿå‹•")
    logger.info("=" * 60)

    # Get target date
    target_date = get_target_date(args.date)
    logger.info(f"ç›®æ¨™æ—¥æœŸ: {target_date}")

    # Determine mode
    if args.dry_run:
        mode = "dry-run"
    elif args.publish_live:
        mode = "publish-live (send newsletter)"
    else:
        mode = "publish (draft)"
    logger.info(f"æ¨¡å¼: {mode}")

    try:
        # Load configuration
        config = None
        ghost_config = None

        if args.publish or args.publish_live:
            config = load_config()
            ghost_config = config.ghost
        elif not args.no_fmp:
            # Try to load FMP config for dry-run
            try:
                config = load_config()
            except Exception:
                logger.info("æœªè¨­å®šç’°å¢ƒè®Šæ•¸ï¼Œä½¿ç”¨ä½”ä½å…§å®¹")

        # Determine if we should use FMP
        use_fmp = not args.no_fmp and config is not None and config.fmp is not None

        # Generate articles
        logger.info("ç”Ÿæˆæ–‡ç« ...")
        articles = generate_articles(target_date, config, use_fmp=use_fmp)
        logger.info(f"å·²ç”Ÿæˆ {len(articles)} ç¯‡æ–‡ç« ")

        # QA Gate (v9) - run before publishing
        from app.ops.qa_gate import run_qa_gate, save_qa_report

        qa_articles = [
            (a.article_num, a.markdown_content) for a in articles
        ]
        qa_report = run_qa_gate(qa_articles, target_date)

        output_dir = Path(args.output_dir)
        save_qa_report(qa_report, output_dir / target_date.strftime("%Y-%m-%d"))

        if qa_report.status == "fail" and not args.dry_run:
            logger.warning(f"QA Gate failed with {len(qa_report.errors)} errors")
            for error in qa_report.errors:
                logger.warning(f"  [{error.code}] Article {error.article_num}: {error.message}")
            # Send QA failure alert (v10)
            from app.ops.alerts import alert_on_qa_fail
            alert_on_qa_fail(qa_report.to_json())
            # Don't block, just warn - uncomment below to block publishing
            # raise ValueError(f"QA Gate failed: {len(qa_report.errors)} errors")
        else:
            logger.info(f"QA Gate: {qa_report.status.upper()} ({qa_report.passed}/{qa_report.articles_checked} passed)")

        # Publish or dry-run

        # Determine if publishing as draft (default) or live
        as_draft = not args.publish_live

        results = publish_articles(
            articles=articles,
            target_date=target_date,
            config=ghost_config,
            dry_run=args.dry_run,
            output_dir=output_dir,
            as_draft=as_draft,
        )

        # Summary
        elapsed = time.time() - start_time
        logger.info("=" * 60)
        logger.info("åŸ·è¡Œå®Œæˆ")
        logger.info(f"è€—æ™‚: {elapsed:.2f} ç§’")
        for article_num, result in sorted(results.items()):
            status = result.get("status", "unknown")
            if status == "dry_run":
                logger.info(f"  æ–‡ç«  {article_num}: {result['md_path']}")
            elif status in ("draft", "published"):
                status_label = "è‰ç¨¿" if status == "draft" else "å·²ç™¼ä½ˆ"
                logger.info(f"  æ–‡ç«  {article_num} [{status_label}]: {result['url']}")
                if result.get("newsletter_sent"):
                    logger.info(f"    -> Newsletter å·²å¯„å‡º")
            else:
                logger.error(f"  æ–‡ç«  {article_num}: {result.get('error', 'unknown error')}")
        logger.info("=" * 60)

        # Success alert (v10) - only if configured
        from app.ops.alerts import alert_on_success
        alert_on_success()

        return 0

    except Exception as e:
        logger.exception(f"åŸ·è¡Œå¤±æ•—: {e}")

        # Failure alert (v10)
        from app.ops.alerts import alert_on_failure
        alert_on_failure(
            error_message=str(e),
            details={"date": target_date.isoformat() if 'target_date' in dir() else None},
        )

        return 1


def main():
    """Entry point."""
    args = parse_args()
    sys.exit(run(args))


if __name__ == "__main__":
    main()
